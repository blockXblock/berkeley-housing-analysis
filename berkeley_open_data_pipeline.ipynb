{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Berkeley Open Data Analysis Pipeline\n",
    "## Integration with Datasette, Pandas, NumPy, TensorFlow, Plotly, and Seaborn\n",
    "\n",
    "**Created:** 2025-01-13  \n",
    "**Purpose:** Fetch, analyze, and visualize City of Berkeley Open Data\n",
    "\n",
    "### Workflow:\n",
    "1. Connect to Berkeley Open Data API (Socrata)\n",
    "2. Fetch Business Licenses and other datasets\n",
    "3. Clean and process data\n",
    "4. Export to CSV, JSON, GeoJSON\n",
    "5. Load into Datasette (SQLite)\n",
    "6. Analyze with Pandas/NumPy\n",
    "7. Visualize with Plotly/Seaborn\n",
    "8. Optional: ML with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (2.1.3)\n",
      "Requirement already satisfied: geopandas in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (1.1.1)\n",
      "Requirement already satisfied: sodapy in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (2.2.0)\n",
      "Requirement already satisfied: datasette in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (0.65.2)\n",
      "Requirement already satisfied: plotly in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (6.4.0)\n",
      "Requirement already satisfied: seaborn in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (0.13.2)\n",
      "Requirement already satisfied: tensorflow in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (2.20.0)\n",
      "Requirement already satisfied: folium in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (0.20.0)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: pyogrio>=0.7.2 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from geopandas) (0.11.1)\n",
      "Requirement already satisfied: packaging in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from geopandas) (24.2)\n",
      "Requirement already satisfied: pyproj>=3.5.0 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from geopandas) (3.7.2)\n",
      "Requirement already satisfied: shapely>=2.0.0 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from geopandas) (2.1.2)\n",
      "Requirement already satisfied: asgiref>=3.2.10 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from datasette) (3.10.0)\n",
      "Requirement already satisfied: click>=7.1.1 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from datasette) (8.3.0)\n",
      "Requirement already satisfied: click-default-group>=1.2.3 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from datasette) (1.2.4)\n",
      "Requirement already satisfied: Jinja2>=2.10.3 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from datasette) (3.1.4)\n",
      "Requirement already satisfied: hupper>=1.9 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from datasette) (1.12.1)\n",
      "Requirement already satisfied: httpx>=0.20 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from datasette) (0.27.0)\n",
      "Requirement already satisfied: pluggy>=1.0 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from datasette) (1.6.0)\n",
      "Requirement already satisfied: uvicorn>=0.11 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from datasette) (0.38.0)\n",
      "Requirement already satisfied: aiofiles>=0.4 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from datasette) (25.1.0)\n",
      "Requirement already satisfied: janus>=0.6.2 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from datasette) (2.0.0)\n",
      "Requirement already satisfied: asgi-csrf>=0.9 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from datasette) (0.11)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from datasette) (6.0.2)\n",
      "Requirement already satisfied: mergedeep>=1.1.1 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from datasette) (1.3.4)\n",
      "Requirement already satisfied: itsdangerous>=1.1 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from datasette) (2.2.0)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from datasette) (72.1.0)\n",
      "Requirement already satisfied: pip in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from datasette) (24.2)\n",
      "Requirement already satisfied: platformdirs>=2.1.0 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from datasette) (3.10.0)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from datasette) (4.12.2)\n",
      "Requirement already satisfied: flexcache>=0.3 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from datasette) (0.3)\n",
      "Requirement already satisfied: flexparser>=0.3 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from datasette) (0.4)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from plotly) (2.11.0)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from seaborn) (3.10.7)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from tensorflow) (6.33.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from tensorflow) (3.2.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from tensorflow) (2.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from tensorflow) (1.76.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from tensorflow) (3.12.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from tensorflow) (3.15.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: branca>=0.6.0 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from folium) (0.8.2)\n",
      "Requirement already satisfied: xyzservices in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from folium) (2025.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from requests) (2024.12.14)\n",
      "Requirement already satisfied: python-multipart>=0.0.13 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from asgi-csrf>=0.9->datasette) (0.0.20)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: anyio in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from httpx>=0.20->datasette) (4.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from httpx>=0.20->datasette) (1.0.2)\n",
      "Requirement already satisfied: sniffio in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from httpx>=0.20->datasette) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.20->datasette) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from Jinja2>=2.10.3->datasette) (2.1.3)\n",
      "Requirement already satisfied: rich in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\n",
      "Requirement already satisfied: namex in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.60.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: pillow>=8 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "‚úÖ Installation complete!\n"
     ]
    }
   ],
   "source": [
    "# CELL 1: Install Required Packages\n",
    "# Run this cell once to install all dependencies\n",
    "\n",
    "%pip install pandas numpy geopandas sodapy datasette plotly seaborn tensorflow folium requests --break-system-packages\n",
    "\n",
    "print(\"‚úÖ Installation complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All libraries imported successfully\n",
      "Pandas version: 2.2.3\n",
      "NumPy version: 2.1.3\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from sodapy import Socrata\n",
    "import json\n",
    "import sqlite3\n",
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully\")\n",
    "print(f\"Pandas version: {pd.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded .env file\n",
      "‚úÖ App token loaded: sKTwtTUl...\n",
      "\n",
      "‚úÖ Connected to data.cityofberkeley.info\n",
      "   Using app token (10,000 requests/hour)\n",
      "\n",
      "üìä Available datasets: ['business_licenses', 'crime_incidents', 'restaurant_inspections', 'building_permits']\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: Configure Berkeley Open Data API - new\n",
    "# CELL 3: Configure Berkeley Open Data API\n",
    "\n",
    "# üîë IMPORTANT: You Need a Free App Token!\n",
    "# \n",
    "# Berkeley's API requires authentication. Get your FREE token here:\n",
    "# https://data.cityofberkeley.info/profile/edit/developer_settings\n",
    "# \n",
    "# It takes 2 minutes and is completely free!\n",
    "# \n",
    "# Quick Setup:\n",
    "# 1. Create account at https://data.cityofberkeley.info\n",
    "# 2. Go to Developer Settings\n",
    "# 3. Create New App Token\n",
    "# 4. Copy your token\n",
    "# 5. Either:\n",
    "#    - Create .env file with: BERKELEY_APP_TOKEN=your-token\n",
    "#    - OR paste token directly below\n",
    "# \n",
    "# See TOKEN_SETUP_INSTRUCTIONS.md for detailed help!\n",
    "\n",
    "import os\n",
    "\n",
    "# Try to load from environment variable first\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    print(\"‚úÖ Loaded .env file\")\n",
    "except:\n",
    "    print(\"‚ÑπÔ∏è  python-dotenv not installed (optional)\")\n",
    "\n",
    "# Berkeley Open Data Portal Configuration\n",
    "BERKELEY_DOMAIN = \"data.cityofberkeley.info\"\n",
    "\n",
    "# üîë SET YOUR APP TOKEN HERE\n",
    "# Get your free token from: https://data.cityofberkeley.info/profile/edit/developer_settings\n",
    "\n",
    "# Option 1: From environment variable (recommended - keeps token private)\n",
    "APP_TOKEN = os.environ.get('BERKELEY_APP_TOKEN')\n",
    "\n",
    "# Option 2: Paste directly here (quick, but less secure if sharing)\n",
    "# Uncomment the line below and add your token:\n",
    "APP_TOKEN = \"sKTwtTUlhd2VfrmCC9W3xKr9P\"  # Replace with your actual token\n",
    "\n",
    "# Check if token is set\n",
    "if APP_TOKEN:\n",
    "    print(f\"‚úÖ App token loaded: {APP_TOKEN[:8]}...\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚ö†Ô∏è  WARNING: No app token found!\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nYou need a FREE app token to access Berkeley's data.\")\n",
    "    print(\"\\nüìù Quick Setup (2 minutes):\")\n",
    "    print(\"   1. Go to: https://data.cityofberkeley.info\")\n",
    "    print(\"   2. Sign up (free)\")\n",
    "    print(\"   3. Developer Settings ‚Üí Create App Token\")\n",
    "    print(\"   4. Copy token and either:\")\n",
    "    print(\"      - Create .env file with: BERKELEY_APP_TOKEN=your-token\")\n",
    "    print(\"      - Or paste directly in this cell (see Option 2 above)\")\n",
    "    print(\"\\nüìñ See TOKEN_SETUP_INSTRUCTIONS.md for detailed help\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\n‚ÑπÔ∏è  Continuing without token - may get 403 errors...\")\n",
    "\n",
    "# CORRECTED Dataset IDs\n",
    "DATASETS = {\n",
    "    'business_licenses': 'rwnf-bu3w',  # ‚úÖ CORRECT ID\n",
    "    'crime_incidents': 'k2nh-s5h5',\n",
    "    'restaurant_inspections': 'b47j-kakm',\n",
    "    'building_permits': 'ydr8-5enu',\n",
    "}\n",
    "\n",
    "# Initialize Socrata client\n",
    "from sodapy import Socrata\n",
    "\n",
    "client = Socrata(BERKELEY_DOMAIN, APP_TOKEN)\n",
    "\n",
    "print(f\"\\n‚úÖ Connected to {BERKELEY_DOMAIN}\")\n",
    "if APP_TOKEN:\n",
    "    print(\"   Using app token (10,000 requests/hour)\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è  No token - limited to 1,000 requests/hour and may be blocked\")\n",
    "print(f\"\\nüìä Available datasets: {list(DATASETS.keys())}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Functions defined\n"
     ]
    }
   ],
   "source": [
    "# CELL 4: Functions for Data Fetching\n",
    "\n",
    "def fetch_berkeley_data(dataset_name, limit=10000, filters=None):\n",
    "    \"\"\"\n",
    "    Fetch data from Berkeley Open Data Portal\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dataset_name : str\n",
    "        Name of dataset from DATASETS dict\n",
    "    limit : int\n",
    "        Maximum number of records to fetch\n",
    "    filters : dict\n",
    "        Optional filters (e.g., {'city': 'Berkeley'})\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame\n",
    "    \"\"\"\n",
    "    try:\n",
    "        dataset_id = DATASETS.get(dataset_name)\n",
    "        if not dataset_id:\n",
    "            raise ValueError(f\"Unknown dataset: {dataset_name}\")\n",
    "        \n",
    "        print(f\"üì• Fetching {dataset_name} from Berkeley Open Data...\")\n",
    "        \n",
    "        # Build query parameters\n",
    "        params = {\"$limit\": limit}\n",
    "        if filters:\n",
    "            # Convert filters to SoQL WHERE clause\n",
    "            where_clauses = [f\"{k}='{v}'\" for k, v in filters.items()]\n",
    "            params[\"$where\"] = \" AND \".join(where_clauses)\n",
    "        \n",
    "        # Fetch data\n",
    "        results = client.get(dataset_id, **params)\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame.from_records(results)\n",
    "        \n",
    "        print(f\"‚úÖ Fetched {len(df)} records\")\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error fetching data: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"‚úÖ Functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Fetching business_licenses from Berkeley Open Data...\n",
      "‚úÖ Fetched 13004 records\n",
      "‚úÖ BL-005071 found!\n",
      "              apn   recordid        busdesc b1_per_sub_type              dba  \\\n",
      "68  052 157301400  BL-005071  OPTICAL STORE    Retail Trade  FOCAL POINT INC   \n",
      "\n",
      "                            naics tax_code employee_num bus_own_type  \\\n",
      "68  446130 - Optical Goods Stores        R            6  Corporation   \n",
      "\n",
      "   b1_business_name          b1_address1   b1_city b1_state     b1_zip  \\\n",
      "68  FOCAL POINT INC  2700 RYDIN RD STE A  RICHMOND       CA  948045800   \n",
      "\n",
      "   b1_contact_type b1_full_address b1_situs_city b1_situs_state b1_situs_zip  \\\n",
      "68  Business Owner  2638 ASHBY AVE      BERKELEY             CA        94705   \n",
      "\n",
      "   b1_address2  \n",
      "68         NaN  \n",
      "\n",
      "üìä Dataset Info:\n",
      "Shape: (13004, 20)\n",
      "\n",
      "Columns: ['apn', 'recordid', 'busdesc', 'b1_per_sub_type', 'dba', 'naics', 'tax_code', 'employee_num', 'bus_own_type', 'b1_business_name', 'b1_address1', 'b1_city', 'b1_state', 'b1_zip', 'b1_contact_type', 'b1_full_address', 'b1_situs_city', 'b1_situs_state', 'b1_situs_zip', 'b1_address2']\n",
      "\n",
      "First few records:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apn</th>\n",
       "      <th>recordid</th>\n",
       "      <th>busdesc</th>\n",
       "      <th>b1_per_sub_type</th>\n",
       "      <th>dba</th>\n",
       "      <th>naics</th>\n",
       "      <th>tax_code</th>\n",
       "      <th>employee_num</th>\n",
       "      <th>bus_own_type</th>\n",
       "      <th>b1_business_name</th>\n",
       "      <th>b1_address1</th>\n",
       "      <th>b1_city</th>\n",
       "      <th>b1_state</th>\n",
       "      <th>b1_zip</th>\n",
       "      <th>b1_contact_type</th>\n",
       "      <th>b1_full_address</th>\n",
       "      <th>b1_situs_city</th>\n",
       "      <th>b1_situs_state</th>\n",
       "      <th>b1_situs_zip</th>\n",
       "      <th>b1_address2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZZZZZZZZZZZZZ</td>\n",
       "      <td>BL-022624</td>\n",
       "      <td>PAINTING CONTRACTOR</td>\n",
       "      <td>Construction or Contractor</td>\n",
       "      <td>ACCEL PAINTING</td>\n",
       "      <td>238320 - Painting and Wall Covering Contractors</td>\n",
       "      <td>C</td>\n",
       "      <td>2</td>\n",
       "      <td>Corporation</td>\n",
       "      <td>ACCEL PAINTING</td>\n",
       "      <td>106 CORTES CT</td>\n",
       "      <td>HERCULES</td>\n",
       "      <td>CA</td>\n",
       "      <td>94547</td>\n",
       "      <td>Business Owner</td>\n",
       "      <td>0 VARIOUS</td>\n",
       "      <td>BERKELEY</td>\n",
       "      <td>CA</td>\n",
       "      <td>94704</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>059 226001900</td>\n",
       "      <td>BL-026980</td>\n",
       "      <td>FLORIST-OPEN AIR</td>\n",
       "      <td>Retail Trade</td>\n",
       "      <td>EMILA</td>\n",
       "      <td>453110 - Florists</td>\n",
       "      <td>R</td>\n",
       "      <td>4</td>\n",
       "      <td>Sole Ownership</td>\n",
       "      <td>EMILA</td>\n",
       "      <td>8 KERR AVE</td>\n",
       "      <td>BERKELEY</td>\n",
       "      <td>CA</td>\n",
       "      <td>94707</td>\n",
       "      <td>Business Owner</td>\n",
       "      <td>1527 SHATTUCK Ave</td>\n",
       "      <td>BERKELEY</td>\n",
       "      <td>CA</td>\n",
       "      <td>94709</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>057 208501700</td>\n",
       "      <td>BL-010435</td>\n",
       "      <td>AUTO COLLISION REPAIRS</td>\n",
       "      <td>Business Personal Repair Svs</td>\n",
       "      <td>PREMIER AUTOBODY</td>\n",
       "      <td>811111 - General Automotive Repair</td>\n",
       "      <td>B</td>\n",
       "      <td>3</td>\n",
       "      <td>Sole Ownership</td>\n",
       "      <td>PREMIER AUTOBODY</td>\n",
       "      <td>1911 SAN PABLO AVE</td>\n",
       "      <td>BERKELEY</td>\n",
       "      <td>CA</td>\n",
       "      <td>94702</td>\n",
       "      <td>Business Owner</td>\n",
       "      <td>1911 SAN PABLO AVE</td>\n",
       "      <td>BERKELEY</td>\n",
       "      <td>CA</td>\n",
       "      <td>94702</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>058 218600700</td>\n",
       "      <td>BL-022111</td>\n",
       "      <td>RES RENTAL - 15 UNITS</td>\n",
       "      <td>Rental of Real Property</td>\n",
       "      <td>FINGADO PAMELA</td>\n",
       "      <td>531110 - Lessors of Residential Buildings and ...</td>\n",
       "      <td>L</td>\n",
       "      <td>0</td>\n",
       "      <td>Sole Ownership</td>\n",
       "      <td>FINGADO PAMELA</td>\n",
       "      <td>851 SEA VIEW DR</td>\n",
       "      <td>EL CERRITO</td>\n",
       "      <td>CA</td>\n",
       "      <td>94530</td>\n",
       "      <td>Business Owner</td>\n",
       "      <td>2355 HILGARD Ave</td>\n",
       "      <td>BERKELEY</td>\n",
       "      <td>CA</td>\n",
       "      <td>94709</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>053 170104902</td>\n",
       "      <td>BL-015919</td>\n",
       "      <td>RECORDING &amp; PROD. SVCS</td>\n",
       "      <td>Entertainment Recreation</td>\n",
       "      <td>BOP CITY MUSIC</td>\n",
       "      <td>512240 - Sound Recording Studios</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "      <td>LLC</td>\n",
       "      <td>BOP CITY MUSIC</td>\n",
       "      <td>2827 RUSSELL ST</td>\n",
       "      <td>BERKELEY</td>\n",
       "      <td>CA</td>\n",
       "      <td>94705-2345</td>\n",
       "      <td>Business Owner</td>\n",
       "      <td>2827 RUSSELL St</td>\n",
       "      <td>BERKELEY</td>\n",
       "      <td>CA</td>\n",
       "      <td>94705</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             apn   recordid                 busdesc  \\\n",
       "0  ZZZZZZZZZZZZZ  BL-022624     PAINTING CONTRACTOR   \n",
       "1  059 226001900  BL-026980        FLORIST-OPEN AIR   \n",
       "2  057 208501700  BL-010435  AUTO COLLISION REPAIRS   \n",
       "3  058 218600700  BL-022111   RES RENTAL - 15 UNITS   \n",
       "4  053 170104902  BL-015919  RECORDING & PROD. SVCS   \n",
       "\n",
       "                b1_per_sub_type               dba  \\\n",
       "0    Construction or Contractor    ACCEL PAINTING   \n",
       "1                  Retail Trade             EMILA   \n",
       "2  Business Personal Repair Svs  PREMIER AUTOBODY   \n",
       "3       Rental of Real Property    FINGADO PAMELA   \n",
       "4      Entertainment Recreation    BOP CITY MUSIC   \n",
       "\n",
       "                                               naics tax_code employee_num  \\\n",
       "0    238320 - Painting and Wall Covering Contractors        C            2   \n",
       "1                                  453110 - Florists        R            4   \n",
       "2                 811111 - General Automotive Repair        B            3   \n",
       "3  531110 - Lessors of Residential Buildings and ...        L            0   \n",
       "4                   512240 - Sound Recording Studios        E            0   \n",
       "\n",
       "     bus_own_type  b1_business_name         b1_address1     b1_city b1_state  \\\n",
       "0     Corporation    ACCEL PAINTING       106 CORTES CT    HERCULES       CA   \n",
       "1  Sole Ownership             EMILA          8 KERR AVE    BERKELEY       CA   \n",
       "2  Sole Ownership  PREMIER AUTOBODY  1911 SAN PABLO AVE    BERKELEY       CA   \n",
       "3  Sole Ownership    FINGADO PAMELA     851 SEA VIEW DR  EL CERRITO       CA   \n",
       "4             LLC    BOP CITY MUSIC     2827 RUSSELL ST    BERKELEY       CA   \n",
       "\n",
       "       b1_zip b1_contact_type     b1_full_address b1_situs_city  \\\n",
       "0       94547  Business Owner           0 VARIOUS      BERKELEY   \n",
       "1       94707  Business Owner   1527 SHATTUCK Ave      BERKELEY   \n",
       "2       94702  Business Owner  1911 SAN PABLO AVE      BERKELEY   \n",
       "3       94530  Business Owner    2355 HILGARD Ave      BERKELEY   \n",
       "4  94705-2345  Business Owner     2827 RUSSELL St      BERKELEY   \n",
       "\n",
       "  b1_situs_state b1_situs_zip b1_address2  \n",
       "0             CA        94704         NaN  \n",
       "1             CA        94709         NaN  \n",
       "2             CA        94702         NaN  \n",
       "3             CA        94709         NaN  \n",
       "4             CA        94705         NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è No location column found\n"
     ]
    }
   ],
   "source": [
    "# CELL 5: Fetch Business Licenses Data \n",
    "\n",
    "# Fetch all business licenses\n",
    "business_licenses = fetch_berkeley_data('business_licenses', limit=50000)\n",
    "\n",
    "# Verify BL-005071 is there\n",
    "if business_licenses is not None:\n",
    "    bl_005071 = business_licenses[business_licenses['recordid'] == 'BL-005071']\n",
    "    if len(bl_005071) > 0:\n",
    "        print(\"‚úÖ BL-005071 found!\")\n",
    "        print(bl_005071)\n",
    "    else:\n",
    "        print(\"‚ùå BL-005071 not in data\")\n",
    "\n",
    "if business_licenses is not None:\n",
    "    # Display basic info\n",
    "    print(\"\\nüìä Dataset Info:\")\n",
    "    print(f\"Shape: {business_licenses.shape}\")\n",
    "    print(f\"\\nColumns: {business_licenses.columns.tolist()}\")\n",
    "    print(f\"\\nFirst few records:\")\n",
    "    display(business_licenses.head())\n",
    "    \n",
    "    # Check for location data\n",
    "    if 'location' in business_licenses.columns:\n",
    "        print(\"\\n‚úÖ Location data available for mapping\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è No location column found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data cleaned. Shape: (13004, 21)\n",
      "\n",
      "üìã Sample cleaned data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordid</th>\n",
       "      <th>b1_business_name</th>\n",
       "      <th>b1_full_address</th>\n",
       "      <th>busdesc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BL-022624</td>\n",
       "      <td>ACCEL PAINTING</td>\n",
       "      <td>0 VARIOUS</td>\n",
       "      <td>PAINTING CONTRACTOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BL-026980</td>\n",
       "      <td>EMILA</td>\n",
       "      <td>1527 SHATTUCK Ave</td>\n",
       "      <td>FLORIST-OPEN AIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BL-010435</td>\n",
       "      <td>PREMIER AUTOBODY</td>\n",
       "      <td>1911 SAN PABLO AVE</td>\n",
       "      <td>AUTO COLLISION REPAIRS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BL-022111</td>\n",
       "      <td>FINGADO PAMELA</td>\n",
       "      <td>2355 HILGARD Ave</td>\n",
       "      <td>RES RENTAL - 15 UNITS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BL-015919</td>\n",
       "      <td>BOP CITY MUSIC</td>\n",
       "      <td>2827 RUSSELL St</td>\n",
       "      <td>RECORDING &amp; PROD. SVCS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    recordid  b1_business_name     b1_full_address                 busdesc\n",
       "0  BL-022624    ACCEL PAINTING           0 VARIOUS     PAINTING CONTRACTOR\n",
       "1  BL-026980             EMILA   1527 SHATTUCK Ave        FLORIST-OPEN AIR\n",
       "2  BL-010435  PREMIER AUTOBODY  1911 SAN PABLO AVE  AUTO COLLISION REPAIRS\n",
       "3  BL-022111    FINGADO PAMELA    2355 HILGARD Ave   RES RENTAL - 15 UNITS\n",
       "4  BL-015919    BOP CITY MUSIC     2827 RUSSELL St  RECORDING & PROD. SVCS"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CELL 6: Data Cleaning & Processing new\n",
    "# CELL 6: Data Cleaning & Processing\n",
    "\n",
    "def clean_business_data(df):\n",
    "    \"\"\"Clean and process business license data\"\"\"\n",
    "    df_clean = df.copy()\n",
    "    \n",
    "    # Normalize APN for joining with parcels\n",
    "    if 'apn' in df_clean.columns:\n",
    "        df_clean['apn_normalized'] = df_clean['apn'].astype(str).str.strip()\n",
    "    \n",
    "    # Parse business_location if it exists (it's a Location type with coordinates)\n",
    "    if 'business_location' in df_clean.columns:\n",
    "        try:\n",
    "            # business_location is a dict with latitude/longitude\n",
    "            import json\n",
    "            \n",
    "            def extract_coords(loc):\n",
    "                if pd.isna(loc):\n",
    "                    return None, None\n",
    "                try:\n",
    "                    if isinstance(loc, str):\n",
    "                        loc = json.loads(loc)\n",
    "                    if isinstance(loc, dict):\n",
    "                        return loc.get('latitude'), loc.get('longitude')\n",
    "                except:\n",
    "                    pass\n",
    "                return None, None\n",
    "            \n",
    "            df_clean[['latitude', 'longitude']] = df_clean['business_location'].apply(\n",
    "                lambda x: pd.Series(extract_coords(x))\n",
    "            )\n",
    "            \n",
    "            coord_count = df_clean['latitude'].notna().sum()\n",
    "            print(f\"‚úÖ Extracted coordinates from business_location: {coord_count} records\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è  Could not parse business_location: {e}\")\n",
    "    \n",
    "    # Convert date columns to datetime\n",
    "    for col in df_clean.columns:\n",
    "        if 'date' in col.lower():\n",
    "            try:\n",
    "                df_clean[col] = pd.to_datetime(df_clean[col])\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    print(f\"‚úÖ Data cleaned.function return Shape: {df_clean.shape}\")\n",
    "    \n",
    "    return df_clean\n",
    "\n",
    "# Clean the data\n",
    "if business_licenses is not None:\n",
    "    business_licenses_clean = clean_business_data(business_licenses)\n",
    "    # look at new data\n",
    "    print(f\"Look at new Shape: {business_licenses_clean.shape}\")\n",
    "    print(f\"\\nColumns: {business_licenses_clean.columns.tolist()}\")\n",
    "\n",
    "    \n",
    "    # Show sample with correct column names\n",
    "    display_cols = ['recordid', 'b1_business_name', 'b1_full_address', 'busdesc', 'dba']\n",
    "    available_cols = [col for col in display_cols if col in business_licenses_clean.columns]\n",
    "    \n",
    "    print(\"\\nüìã Sample new cleaned data:\")\n",
    "    display(business_licenses_clean[available_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CSV exported: /Users/johngage/berkeley-data/business_licenses_20251115.csv\n",
      "‚úÖ JSON exported: /Users/johngage/berkeley-data/business_licenses_20251115.json\n",
      "\n",
      "üìä Exported 13004 business licenses\n"
     ]
    }
   ],
   "source": [
    "# CELL 7: Export to Multiple Formats-new\n",
    "# CELL 7: Export to Multiple Formats\n",
    "\n",
    "if business_licenses_clean is not None:\n",
    "    # Create output directory\n",
    "    output_dir = Path('/Users/johngage/berkeley-data')\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d\")\n",
    "    \n",
    "    # Export to CSV\n",
    "    csv_path = output_dir / f'business_licenses_{timestamp}.csv'\n",
    "    business_licenses_clean.to_csv(csv_path, index=False)\n",
    "    print(f\"‚úÖ CSV exported: {csv_path}\")\n",
    "    \n",
    "    # Export to JSON\n",
    "    json_path = output_dir / f'business_licenses_{timestamp}.json'\n",
    "    business_licenses_clean.to_json(json_path, orient='records', indent=2)\n",
    "    print(f\"‚úÖ JSON exported: {json_path}\")\n",
    "    \n",
    "    # Export to GeoJSON if coordinates exist\n",
    "    if 'latitude' in business_licenses_clean.columns and 'longitude' in business_licenses_clean.columns:\n",
    "        geo_df = business_licenses_clean.dropna(subset=['latitude', 'longitude'])\n",
    "        \n",
    "        if len(geo_df) > 0:\n",
    "            import geopandas as gpd\n",
    "            gdf = gpd.GeoDataFrame(\n",
    "                geo_df,\n",
    "                geometry=gpd.points_from_xy(geo_df.longitude, geo_df.latitude),\n",
    "                crs='EPSG:4326'\n",
    "            )\n",
    "            \n",
    "            geojson_path = output_dir / f'business_licenses_{timestamp}.geojson'\n",
    "            gdf.to_file(geojson_path, driver='GeoJSON')\n",
    "            print(f\"‚úÖ GeoJSON exported: {geojson_path} ({len(gdf)} records)\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  No coordinates available for GeoJSON export\")\n",
    "    \n",
    "    print(f\"\\nüìä Exported {len(business_licenses_clean)} business licenses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Loaded 13004 records into table 'licenses'\n",
      "   Database: ./berkeley.db\n",
      "‚úÖ Created indexes on: recordid, b1_business_name, apn\n"
     ]
    }
   ],
   "source": [
    "# CELL 8: Load Data into Datasette (SQLite) - new\n",
    "\n",
    "# CELL 8: Load Data into Datasette (SQLite)\n",
    "\n",
    "def load_to_datasette(df, table_name, db_path='./berkeley.db'):\n",
    "    \"\"\"Load DataFrame into SQLite database for Datasette\"\"\"\n",
    "    import sqlite3\n",
    "    \n",
    "    # Prepare for SQLite\n",
    "    df_for_db = df.copy()\n",
    "    \n",
    "    # Convert datetime to string\n",
    "    for col in df_for_db.select_dtypes(include=['datetime64']).columns:\n",
    "        df_for_db[col] = df_for_db[col].astype(str)\n",
    "    \n",
    "    # Drop complex objects (business_location if it's still a dict)\n",
    "    if 'business_location' in df_for_db.columns:\n",
    "        try:\n",
    "            # Try to convert to string if it's a dict/json\n",
    "            df_for_db['business_location'] = df_for_db['business_location'].astype(str)\n",
    "        except:\n",
    "            df_for_db = df_for_db.drop('business_location', axis=1)\n",
    "    \n",
    "    # Connect to SQLite\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    \n",
    "    # Load data\n",
    "    df_for_db.to_sql(table_name, conn, if_exists='replace', index=False)\n",
    "    \n",
    "    # Create indexes on key columns (using correct API field names)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    if 'b1_business_name' in df_for_db.columns:\n",
    "        cursor.execute(f\"CREATE INDEX IF NOT EXISTS idx_business_name ON {table_name}(b1_business_name)\")\n",
    "    \n",
    "    if 'apn_normalized' in df_for_db.columns:\n",
    "        cursor.execute(f\"CREATE INDEX IF NOT EXISTS idx_apn ON {table_name}(apn_normalized)\")\n",
    "    elif 'apn' in df_for_db.columns:\n",
    "        cursor.execute(f\"CREATE INDEX IF NOT EXISTS idx_apn ON {table_name}(apn)\")\n",
    "    \n",
    "    if 'recordid' in df_for_db.columns:\n",
    "        cursor.execute(f\"CREATE INDEX IF NOT EXISTS idx_recordid ON {table_name}(recordid)\")\n",
    "    \n",
    "    if 'b1_zip' in df_for_db.columns:\n",
    "        cursor.execute(f\"CREATE INDEX IF NOT EXISTS idx_zip ON {table_name}(b1_zip)\")\n",
    "    \n",
    "    if 'latitude' in df_for_db.columns:\n",
    "        cursor.execute(f\"CREATE INDEX IF NOT EXISTS idx_lat ON {table_name}(latitude)\")\n",
    "    \n",
    "    if 'longitude' in df_for_db.columns:\n",
    "        cursor.execute(f\"CREATE INDEX IF NOT EXISTS idx_lon ON {table_name}(longitude)\")\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {len(df_for_db)} records into table '{table_name}'\")\n",
    "    print(f\"   Database: {db_path}\")\n",
    "    \n",
    "    # Show which indexes were created\n",
    "    index_cols = []\n",
    "    if 'recordid' in df_for_db.columns: index_cols.append('recordid')\n",
    "    if 'b1_business_name' in df_for_db.columns: index_cols.append('b1_business_name')\n",
    "    if 'apn_normalized' in df_for_db.columns or 'apn' in df_for_db.columns: index_cols.append('apn')\n",
    "    if 'latitude' in df_for_db.columns: index_cols.append('latitude')\n",
    "    \n",
    "    print(f\"‚úÖ Created indexes on: {', '.join(index_cols)}\")\n",
    "\n",
    "if business_licenses_clean is not None:\n",
    "    load_to_datasette(business_licenses_clean, 'licenses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Running SQL Queries:\n",
      "\n",
      "Top 10 Business Types:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_type</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GENERAL CONTRACTOR</td>\n",
       "      <td>609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COMMERCIAL RENTAL</td>\n",
       "      <td>586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RENTAL PROPERTY</td>\n",
       "      <td>333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ELECTRICAL CONTRACTOR</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RES. RENTAL - 4 UNITS</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ROOFING CONTRACTOR</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RES. RENTAL - 3 UNITS</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RESTAURANT</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PLUMBING CONTRACTOR</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PSYCHOTHERAPY</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           business_type  count\n",
       "0     GENERAL CONTRACTOR    609\n",
       "1      COMMERCIAL RENTAL    586\n",
       "2        RENTAL PROPERTY    333\n",
       "3  ELECTRICAL CONTRACTOR    290\n",
       "4  RES. RENTAL - 4 UNITS    202\n",
       "5     ROOFING CONTRACTOR    146\n",
       "6  RES. RENTAL - 3 UNITS    140\n",
       "7             RESTAURANT    131\n",
       "8    PLUMBING CONTRACTOR    124\n",
       "9          PSYCHOTHERAPY    120"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Top 10 ZIP Codes:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip_code</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>94703</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94705</td>\n",
       "      <td>391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>94710</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94702</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>94704</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>94709</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>94707</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>94706</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>94708</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>94530</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  zip_code  count\n",
       "0    94703    393\n",
       "1    94705    391\n",
       "2    94710    381\n",
       "3    94702    336\n",
       "4    94704    302\n",
       "5    94709    278\n",
       "6    94707    208\n",
       "7    94706     77\n",
       "8    94708     77\n",
       "9    94530     65"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\nSELECT \n    COUNT(*) as total_licenses,\n    COUNT(latitude) as with_coordinates,\n    ROUND(100.0 * COUNT(latitude) / COUNT(*), 1) as percent_mapped\nFROM licenses\n': no such column: latitude",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "File \u001b[0;32m/opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages/pandas/io/sql.py:2674\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2673\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2674\u001b[0m     cur\u001b[38;5;241m.\u001b[39mexecute(sql, \u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   2675\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cur\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such column: latitude",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 51\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Query 3: Check how many have coordinates\u001b[39;00m\n\u001b[1;32m     44\u001b[0m query3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;124mSELECT \u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124m    COUNT(*) as total_licenses,\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124mFROM licenses\u001b[39m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 51\u001b[0m result3 \u001b[38;5;241m=\u001b[39m query_datasette_db(query3)\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCoordinate Coverage:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     53\u001b[0m display(result3)\n",
      "Cell \u001b[0;32mIn[12], line 8\u001b[0m, in \u001b[0;36mquery_datasette_db\u001b[0;34m(query, db_path)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute SQL query on Datasette database\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m conn \u001b[38;5;241m=\u001b[39m sqlite3\u001b[38;5;241m.\u001b[39mconnect(db_path)\n\u001b[0;32m----> 8\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_sql_query(query, conn)\n\u001b[1;32m      9\u001b[0m conn\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages/pandas/io/sql.py:526\u001b[0m, in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m dtype_backend \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mno_default\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pandasSQL_builder(con) \u001b[38;5;28;01mas\u001b[39;00m pandas_sql:\n\u001b[0;32m--> 526\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_query(\n\u001b[1;32m    527\u001b[0m         sql,\n\u001b[1;32m    528\u001b[0m         index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[1;32m    529\u001b[0m         params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    530\u001b[0m         coerce_float\u001b[38;5;241m=\u001b[39mcoerce_float,\n\u001b[1;32m    531\u001b[0m         parse_dates\u001b[38;5;241m=\u001b[39mparse_dates,\n\u001b[1;32m    532\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[1;32m    533\u001b[0m         dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    534\u001b[0m         dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    535\u001b[0m     )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages/pandas/io/sql.py:2738\u001b[0m, in \u001b[0;36mSQLiteDatabase.read_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype, dtype_backend)\u001b[0m\n\u001b[1;32m   2727\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_query\u001b[39m(\n\u001b[1;32m   2728\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   2729\u001b[0m     sql,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2736\u001b[0m     dtype_backend: DtypeBackend \u001b[38;5;241m|\u001b[39m Literal[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2737\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Iterator[DataFrame]:\n\u001b[0;32m-> 2738\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexecute(sql, params)\n\u001b[1;32m   2739\u001b[0m     columns \u001b[38;5;241m=\u001b[39m [col_desc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m col_desc \u001b[38;5;129;01min\u001b[39;00m cursor\u001b[38;5;241m.\u001b[39mdescription]\n\u001b[1;32m   2741\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/jupyter_env/lib/python3.12/site-packages/pandas/io/sql.py:2686\u001b[0m, in \u001b[0;36mSQLiteDatabase.execute\u001b[0;34m(self, sql, params)\u001b[0m\n\u001b[1;32m   2683\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01minner_exc\u001b[39;00m\n\u001b[1;32m   2685\u001b[0m ex \u001b[38;5;241m=\u001b[39m DatabaseError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution failed on sql \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msql\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2686\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m ex \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[0;31mDatabaseError\u001b[0m: Execution failed on sql '\nSELECT \n    COUNT(*) as total_licenses,\n    COUNT(latitude) as with_coordinates,\n    ROUND(100.0 * COUNT(latitude) / COUNT(*), 1) as percent_mapped\nFROM licenses\n': no such column: latitude"
     ]
    }
   ],
   "source": [
    "# CELL 9: Query Data with SQL- new\n",
    "\n",
    "# CELL 9: Query Data with SQL\n",
    "\n",
    "def query_datasette_db(query, db_path='./berkeley.db'):\n",
    "    \"\"\"Execute SQL query on Datasette database\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    df = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    return df\n",
    "\n",
    "print(\"üìä Running SQL Queries:\\n\")\n",
    "\n",
    "# Query 1: Count by business type\n",
    "query1 = \"\"\"\n",
    "SELECT busdesc as business_type, COUNT(*) as count\n",
    "FROM licenses\n",
    "GROUP BY busdesc\n",
    "ORDER BY count DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "result1 = query_datasette_db(query1)\n",
    "print(\"Top 10 Business Types:\")\n",
    "display(result1)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Query 2: Businesses by ZIP code\n",
    "query2 = \"\"\"\n",
    "SELECT b1_zip as zip_code, COUNT(*) as count\n",
    "FROM licenses\n",
    "WHERE b1_zip IS NOT NULL\n",
    "GROUP BY b1_zip\n",
    "ORDER BY count DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "result2 = query_datasette_db(query2)\n",
    "print(\"Top 10 ZIP Codes:\")\n",
    "display(result2)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# Query 3: Check how many have coordinates\n",
    "query3 = \"\"\"\n",
    "SELECT \n",
    "    COUNT(*) as total_licenses,\n",
    "    COUNT(latitude) as with_coordinates,\n",
    "    ROUND(100.0 * COUNT(latitude) / COUNT(*), 1) as percent_mapped\n",
    "FROM licenses\n",
    "\"\"\"\n",
    "result3 = query_datasette_db(query3)\n",
    "print(\"Coordinate Coverage:\")\n",
    "display(result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 10: Data Analysis with Pandas & NumPy - new\n",
    "\n",
    "# CELL 10: Data Analysis with Pandas & NumPy\n",
    "\n",
    "if business_licenses_clean is not None:\n",
    "    print(\"üìä Data Analysis:\\n\")\n",
    "    \n",
    "    # 1. Business types\n",
    "    if 'busdesc' in business_licenses_clean.columns:\n",
    "        print(\"1. Top Business Types:\")\n",
    "        print(business_licenses_clean['busdesc'].value_counts().head(10))\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # 2. Distribution by city\n",
    "    if 'b1_situs_city' in business_licenses_clean.columns:\n",
    "        print(\"2. Businesses by Physical City:\")\n",
    "        print(business_licenses_clean['b1_situs_city'].value_counts())\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # 3. Coordinates coverage\n",
    "    if 'latitude' in business_licenses_clean.columns:\n",
    "        total = len(business_licenses_clean)\n",
    "        with_coords = business_licenses_clean['latitude'].notna().sum()\n",
    "        print(f\"3. Location Coverage:\")\n",
    "        print(f\"   Total businesses: {total:,}\")\n",
    "        print(f\"   With coordinates: {with_coords:,} ({100*with_coords/total:.1f}%)\")\n",
    "        print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "    \n",
    "    # 4. Missing data analysis\n",
    "    print(\"4. Missing Data:\")\n",
    "    missing = business_licenses_clean.isnull().sum()\n",
    "    missing_pct = (missing / len(business_licenses_clean)) * 100\n",
    "    missing_df = pd.DataFrame({\n",
    "        'Missing Count': missing,\n",
    "        'Percentage': missing_pct\n",
    "    }).sort_values('Missing Count', ascending=False)\n",
    "    display(missing_df[missing_df['Missing Count'] > 0].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 11: Visualization with Seaborn\n",
    "\n",
    "if business_licenses_clean is not None and 'business_type' in business_licenses_clean.columns:\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    top_types = business_licenses_clean['business_type'].value_counts().head(15)\n",
    "    sns.barplot(x=top_types.values, y=top_types.index, palette='viridis')\n",
    "    plt.title('Top 15 Business Types in Berkeley', fontsize=14, fontweight='bold')\n",
    "    plt.xlabel('Count')\n",
    "    plt.ylabel('Business Type')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    plt.savefig('/mnt/user-data/outputs/business_types.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"‚úÖ Visualization saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 12: Interactive Visualization with Plotly\n",
    "\n",
    "if business_licenses_clean is not None:\n",
    "    # Interactive bar chart\n",
    "    if 'business_type' in business_licenses_clean.columns:\n",
    "        top_types = business_licenses_clean['business_type'].value_counts().head(20)\n",
    "        \n",
    "        fig = px.bar(\n",
    "            x=top_types.values,\n",
    "            y=top_types.index,\n",
    "            orientation='h',\n",
    "            title='Top 20 Business Types in Berkeley',\n",
    "            labels={'x': 'Number of Businesses', 'y': 'Business Type'},\n",
    "            color=top_types.values,\n",
    "            color_continuous_scale='Viridis'\n",
    "        )\n",
    "        fig.update_layout(height=600, showlegend=False)\n",
    "        fig.show()\n",
    "    \n",
    "    # Interactive map\n",
    "    if 'latitude' in business_licenses_clean.columns and 'longitude' in business_licenses_clean.columns:\n",
    "        map_df = business_licenses_clean.dropna(subset=['latitude', 'longitude']).head(1000)\n",
    "        \n",
    "        if len(map_df) > 0:\n",
    "            fig = px.scatter_mapbox(\n",
    "                map_df,\n",
    "                lat='latitude',\n",
    "                lon='longitude',\n",
    "                hover_name='business_name' if 'business_name' in map_df.columns else None,\n",
    "                zoom=12,\n",
    "                height=600,\n",
    "                title='Berkeley Business Locations (Sample)'\n",
    "            )\n",
    "            fig.update_layout(mapbox_style=\"open-street-map\")\n",
    "            fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 13: Launch Datasette\n",
    "\n",
    "print(\"\"\"\n",
    "üöÄ To launch Datasette server:\n",
    "\n",
    "In a terminal, run:\n",
    "  datasette /mnt/user-data/outputs/berkeley_data.db --host 0.0.0.0 --port 8001\n",
    "\n",
    "Then access at: http://localhost:8001\n",
    "\"\"\")\n",
    "\n",
    "# Create metadata file\n",
    "metadata = {\n",
    "    \"title\": \"Berkeley Open Data\",\n",
    "    \"description\": \"City of Berkeley business licenses and related data\",\n",
    "    \"databases\": {\n",
    "        \"berkeley_data\": {\n",
    "            \"tables\": {\n",
    "                \"business_licenses\": {\n",
    "                    \"title\": \"Business Licenses\",\n",
    "                    \"description\": \"Active business licenses in Berkeley, CA\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "with open('/mnt/user-data/outputs/metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)\n",
    "\n",
    "print(\"‚úÖ Metadata file created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates:\n",
    "- ‚úÖ Fetching data from Berkeley Open Data API\n",
    "- ‚úÖ Data cleaning and processing with Pandas\n",
    "- ‚úÖ Exporting to CSV, JSON, and GeoJSON\n",
    "- ‚úÖ Loading into SQLite for Datasette\n",
    "- ‚úÖ SQL queries for analysis\n",
    "- ‚úÖ Visualizations with Seaborn and Plotly\n",
    "- ‚úÖ Interactive maps\n",
    "\n",
    "### Next Steps:\n",
    "1. Add more datasets from Berkeley Open Data\n",
    "2. Create custom dashboards\n",
    "3. Schedule automated updates\n",
    "4. Integrate with OSMnx for spatial analysis\n",
    "5. Build predictive models with TensorFlow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
